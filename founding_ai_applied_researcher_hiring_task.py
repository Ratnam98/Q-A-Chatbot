# -*- coding: utf-8 -*-
"""Founding AI Applied Researcher -Hiring Task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ju3EsX6xS-VP6aXfytcfqbh_q8d3BDKd
"""

!pip install --upgrade langchain openai  -q

import os

!pip install unstructured -q
!pip install unstructured[local-inference] -q
!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q

!apt-get install poppler-utils

!pip install --upgrade pillow==6.2.2

"""https://python.langchain.com/docs/modules/data_connection/document_loaders"""

from langchain.document_loaders import DirectoryLoader

loader=DirectoryLoader('/content/data')

documents=loader.load()

len(documents)

from langchain.text_splitter import RecursiveCharacterTextSplitter

def split_docs(documents,chunk_size=1000,chunk_overlap=20):
  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
  docs = text_splitter.split_documents(documents)
  return docs

docs = split_docs(documents)
print(len(docs))

print(docs[0].page_content)

print(docs[5].page_content)

#requires for open ai embedding
!pip install tiktoken -q

os.environ["OPENAI_API_KEY"]="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" #Get Your own openai api key from https://platform.openai.com

import openai
from langchain.embeddings.openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()

query_result = embeddings.embed_query("Hello world")
len(query_result)

!pip install pinecone-client -q

import pinecone
from langchain.vectorstores import Pinecone
# initialize pinecone
pinecone.init(
    api_key="7c025a79-30d3-4156-abbb-409591fbd335",  # find at app.pinecone.io
    environment="us-west1-gcp-free"  # next to api key in console
)

index_name = "langchain3"

index = Pinecone.from_documents(docs, embeddings, index_name=index_name)

def get_similiar_docs(query,k=2,score=False):
  if score:
    similar_docs = index.similarity_search_with_score(query,k=k)
  else:
    similar_docs = index.similarity_search(query,k=k)
  return similar_docs

query = "What are the documents required to apply for the new pan"
similar_docs = get_similiar_docs(query)
similar_docs

from langchain.llms import OpenAI

# model_name = "text-davinci-003"
model_name = "gpt-3.5-turbo"
#model_name = "gpt-4"
llm = OpenAI(model_name=model_name)

from langchain.chains.question_answering import load_qa_chain
chain = load_qa_chain(llm, chain_type="stuff")

def get_answer(query):
  similar_docs = get_similiar_docs(query)
  # print(similar_docs)
  answer =  chain.run(input_documents=similar_docs, question=query)
  return  answer

query = "What are the documents required to apply for the new pan"
get_answer(query)

query = "Can I take the delivery of Pan card at Indian address"
get_answer(query)

query="Process to link PAN with Aadhaar"
get_answer(query)

